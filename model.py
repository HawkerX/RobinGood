############################################
# SUPPRESSES tensorflow warnings
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
############################################

from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import pandas as pd
import numpy as np

######### MAGIC VARS ############
# SEQUENCE_LENGTH determines how many past time 
# STEPs the model looks at to predict the next value.
SEQUENCE_LENGTH = 10
EPOCHS = 10
BATCH_SIZE = 2

# plot vars
SCALING_FACTOR = 0.05  # Increase the scaling factor to make vectors larger
STEP = 2  # Only show a vector every 10 dates

# Hyperparameters
UNITS = 100
LR = 0.00020022
DROPOUT = True
DP = 0.018381
DELTA = 1

#############################

# Load the Dataset
data = pd.read_csv('GOOGL_Training_Data.csv') # GOOGL_Training_Data.csv # COCO_COLA.csv
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

########## Calculate additional features ###############
# 1. Percentage Change in Close Price
data['Pct_Change'] = data['Close'].pct_change()

# 2. Moving Averages (5-day and 20-day) # TODO magic vars
data['MA5'] = data['Close'].rolling(window=5).mean()
data['MA20'] = data['Close'].rolling(window=20).mean()

# 3. Relative Strength Index (RSI)
def compute_rsi(data, window=14):
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

data['RSI'] = compute_rsi(data)

# 4. Volatility (difference between High and Low)
data['Volatility'] = data['High'] - data['Low']

##############################################

# Drop NA values generated by rolling windows
data = data.dropna()

# Normalize all features
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Volume', 'Pct_Change', 'MA5', 'MA20', 'RSI', 'Volatility']])

# Convert scaled data back to a DataFrame for easier plotting
scaled_df = pd.DataFrame(scaled_data, columns=['Open', 'High', 'Low', 'Close', 'Volume', 'Pct_Change', 'MA5', 'MA20', 'RSI', 'Volatility'], index=data.index)

# Create Training and Testing Datasets
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

# Preprocess sequences
def preprocess_sequence(sequence):
    # Calculate price diffrence between sequences
    diff = sequence[:, -1] - sequence[:, -2]
    return np.concatenate([sequence, diff.reshape(-1, 1)], axis=-1)

def create_sequences(data, seq_length, target_col_index):
    x, y = [], []
    for i in range(len(data) - seq_length):
        x.append(data[i:i + seq_length])
        # Binary target: 1 if price goes up, 0 if price goes down
        y.append(1 if data[i + seq_length, target_col_index] > data[i + seq_length - 1, target_col_index] else 0)
    return np.array(x), np.array(y)

# We target the 'Close' price for predicting movement
close_column_index = data.columns.get_loc('Close')
x_train, y_train = create_sequences(train_data, SEQUENCE_LENGTH, target_col_index=close_column_index)
x_test, y_test = create_sequences(test_data, SEQUENCE_LENGTH, target_col_index=close_column_index)

# Reshape data to 3D for GRU
x_train = np.reshape(x_train, (x_train.shape[0], SEQUENCE_LENGTH, scaled_data.shape[1]))
x_test = np.reshape(x_test, (x_test.shape[0], SEQUENCE_LENGTH, scaled_data.shape[1]))

# Build the GRU Model
def call_existing_code(units, lr, dropout, dp, delta):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Input(shape=(SEQUENCE_LENGTH + 1, scaled_data.shape[1])))
    model.add(tf.keras.layers.GRU(units=units, return_sequences=True))
    if dropout:
        model.add(tf.keras.layers.Dropout(dp))  # Dropout to prevent overfitting

    model.add(tf.keras.layers.GRU(units=units, return_sequences=False))
    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Sigmoid for binary classification

    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])
    return model

model = call_existing_code(units=UNITS, lr=LR, dropout=DROPOUT, dp=DP, delta=DELTA)
model.summary()

# Early stopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model.fit(
    x_train, y_train, 
    validation_split=0.1,
    batch_size=BATCH_SIZE, 
    epochs=EPOCHS, 
    callbacks=[early_stopping]
)

# Make predictions
preds = model.predict(x_test)

# Convert predictions to binary (1 or 0)
preds_binary = (preds > 0.5).astype(int)
actual = y_test

############### PLOT #################
plt.figure(figsize=(14, 7))
plt.plot(data.index[train_size + SEQUENCE_LENGTH:], data['Close'][train_size + SEQUENCE_LENGTH:], label='Actual Close Price', color='blue')

for i in range(0, len(preds_binary) - 1, STEP):  # STEP through the data at intervals of 'STEP'
    current_close = data['Close'].iloc[train_size + SEQUENCE_LENGTH + i]
    confidence = preds[i] 

    vector_length = SCALING_FACTOR * current_close 
    if preds_binary[i] == 1:  # Predicted movement is up
        plt.quiver(data.index[train_size + SEQUENCE_LENGTH + i], current_close,
                   0, vector_length, angles='xy', scale_units='xy', scale=1, color='green', width=0.005)
    elif preds_binary[i] == 0:  # Predicted movement is down
        plt.quiver(data.index[train_size + SEQUENCE_LENGTH + i], current_close,
                   0, -vector_length, angles='xy', scale_units='xy', scale=1, color='red', width=0.005)

# Adding titles and labels
plt.title('Stock Price Prediction with Larger Vectors (Green = Up, Red = Down)', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Close Price', fontsize=12)
plt.legend()

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Show the plot
plt.tight_layout()
plt.show()
